{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation from generated doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from itertools import combinations\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Load topic results\n",
    "df = pd.read_csv(\"gpu_results5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all entries in 'keywords' are lists, replacing NaN (floats) with empty lists\n",
    "df['keywords'] = df['keywords'].apply(lambda x: x if isinstance(x, str) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>percentage</th>\n",
       "      <th>keywords</th>\n",
       "      <th>document_index</th>\n",
       "      <th>percentence</th>\n",
       "      <th>percenture</th>\n",
       "      <th>key keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Historical Debates and Controversies</td>\n",
       "      <td>40.0</td>\n",
       "      <td>['Turks', 'Armenians', 'Holocaust', 'extermina...</td>\n",
       "      <td>15001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Artificial Intelligence and its Misuse</td>\n",
       "      <td>20.0</td>\n",
       "      <td>['AI', 'stupidity', 'amok', 'compose', 'pointl...</td>\n",
       "      <td>15001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intercultural Communication and Stereotypes</td>\n",
       "      <td>15.0</td>\n",
       "      <td>['insults', 'Typical Mutlu', 'PvdL', 'Cosar']</td>\n",
       "      <td>15001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Internet Discourse and Netiquette</td>\n",
       "      <td>10.0</td>\n",
       "      <td>['article', 'followup', 'alleviate puzzlement'...</td>\n",
       "      <td>15001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Political Opinion and Bias</td>\n",
       "      <td>10.0</td>\n",
       "      <td>['Turks did what they are accused of', 'Armeni...</td>\n",
       "      <td>15001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>Celebrity and Fame</td>\n",
       "      <td>35.0</td>\n",
       "      <td>['Jesse', 'famous', 'intern']</td>\n",
       "      <td>16309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6018</th>\n",
       "      <td>Workplace Relationships</td>\n",
       "      <td>25.0</td>\n",
       "      <td>['work', 'intern', 'Landau']</td>\n",
       "      <td>16309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6019</th>\n",
       "      <td>Spite and Competition</td>\n",
       "      <td>15.0</td>\n",
       "      <td>['like it out of spite', 'Just kidding']</td>\n",
       "      <td>16309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6020</th>\n",
       "      <td>Quotation Analysis</td>\n",
       "      <td>10.0</td>\n",
       "      <td>['skepticism', 'intellect', 'Gordon Banks']</td>\n",
       "      <td>16309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6021</th>\n",
       "      <td>Informal Communication</td>\n",
       "      <td>10.0</td>\n",
       "      <td>['Gosh', 'Bill', 'Just kidding, Bill']</td>\n",
       "      <td>16309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6022 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name  percentage  \\\n",
       "0            Historical Debates and Controversies        40.0   \n",
       "1          Artificial Intelligence and its Misuse        20.0   \n",
       "2     Intercultural Communication and Stereotypes        15.0   \n",
       "3               Internet Discourse and Netiquette        10.0   \n",
       "4                      Political Opinion and Bias        10.0   \n",
       "...                                           ...         ...   \n",
       "6017                           Celebrity and Fame        35.0   \n",
       "6018                      Workplace Relationships        25.0   \n",
       "6019                        Spite and Competition        15.0   \n",
       "6020                           Quotation Analysis        10.0   \n",
       "6021                       Informal Communication        10.0   \n",
       "\n",
       "                                               keywords  document_index  \\\n",
       "0     ['Turks', 'Armenians', 'Holocaust', 'extermina...           15001   \n",
       "1     ['AI', 'stupidity', 'amok', 'compose', 'pointl...           15001   \n",
       "2         ['insults', 'Typical Mutlu', 'PvdL', 'Cosar']           15001   \n",
       "3     ['article', 'followup', 'alleviate puzzlement'...           15001   \n",
       "4     ['Turks did what they are accused of', 'Armeni...           15001   \n",
       "...                                                 ...             ...   \n",
       "6017                      ['Jesse', 'famous', 'intern']           16309   \n",
       "6018                       ['work', 'intern', 'Landau']           16309   \n",
       "6019           ['like it out of spite', 'Just kidding']           16309   \n",
       "6020        ['skepticism', 'intellect', 'Gordon Banks']           16309   \n",
       "6021             ['Gosh', 'Bill', 'Just kidding, Bill']           16309   \n",
       "\n",
       "      percentence  percenture key keywords  \n",
       "0             NaN         NaN          NaN  \n",
       "1             NaN         NaN          NaN  \n",
       "2             NaN         NaN          NaN  \n",
       "3             NaN         NaN          NaN  \n",
       "4             NaN         NaN          NaN  \n",
       "...           ...         ...          ...  \n",
       "6017          NaN         NaN          NaN  \n",
       "6018          NaN         NaN          NaN  \n",
       "6019          NaN         NaN          NaN  \n",
       "6020          NaN         NaN          NaN  \n",
       "6021          NaN         NaN          NaN  \n",
       "\n",
       "[6022 rows x 7 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the keyword list and count occurrences\n",
    "all_keywords = [word for sublist in df['keywords'] for word in sublist]\n",
    "word_counts = Counter(all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute co-occurrence counts\n",
    "co_occurrence_counts = Counter()\n",
    "for keyword_list in df['keywords']:\n",
    "    for word1, word2 in combinations(keyword_list, 2):\n",
    "        co_occurrence_counts[frozenset([word1, word2])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove invalid entries (pairs with fewer than 2 elements)\n",
    "invalid_entries = [pair for pair in co_occurrence_counts.keys() if len(pair) != 2]\n",
    "for pair in invalid_entries:\n",
    "    del co_occurrence_counts[pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute NPMI values\n",
    "npmi_scores = {}\n",
    "total_pairs = sum(co_occurrence_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_pair, co_occ_count in co_occurrence_counts.items():\n",
    "    word1, word2 = list(word_pair)\n",
    "    p_x = word_counts[word1] / len(all_keywords)\n",
    "    p_y = word_counts[word2] / len(all_keywords)\n",
    "    p_xy = co_occ_count / total_pairs\n",
    "\n",
    "    if p_xy > 0:\n",
    "        pmi = np.log(p_xy / (p_x * p_y))\n",
    "        npmi = pmi / -np.log(p_xy)\n",
    "        npmi_scores[word_pair] = npmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Topic Diversity (TD) based on topic names\n",
    "df_grouped = df.groupby(\"document_index\")[\"name\"].apply(list)\n",
    "all_topic_names = [name for sublist in df_grouped for name in sublist]\n",
    "unique_topic_names = set(all_topic_names)\n",
    "total_topic_names = len(all_topic_names)\n",
    "topic_diversity_names = len(unique_topic_names) / total_topic_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average NPMI\n",
    "npmi_avg = np.mean(list(npmi_scores.values())) if npmi_scores else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08467779335128871"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npmi_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8771172367984058"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_diversity_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results = {\n",
    "    \"NPMI Score\": npmi_avg,\n",
    "    \"Topic Diversity\": topic_diversity_names\n",
    "}\n",
    "pd.DataFrame([results]).to_csv(\"bbc_mistral_evaluation.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
